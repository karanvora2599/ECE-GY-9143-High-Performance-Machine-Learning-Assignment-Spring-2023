Processor: Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz
RAM: 175Gi
GPU:     Product Name                          : Quadro RTX 8000
    Product Name                          : Quadro RTX 8000
    Product Name                          : Quadro RTX 8000
    Product Name                          : Quadro RTX 8000
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: typing-extensions in /home/kv2154/.local/lib/python3.8/site-packages (4.5.0)
WARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.
You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: sympy in /home/kv2154/.local/lib/python3.8/site-packages (1.11.1)
Requirement already satisfied: mpmath>=0.19 in /home/kv2154/.local/lib/python3.8/site-packages (from sympy) (1.3.0)
WARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.
You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /home/kv2154/.local/lib/python3.8/site-packages (2.0.0)
Requirement already satisfied: torchvision in /home/kv2154/.local/lib/python3.8/site-packages (0.15.1)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.7.101)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (2.14.3)
Requirement already satisfied: typing-extensions in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (4.5.0)
Requirement already satisfied: sympy in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (1.11.1)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.10.3.66)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (10.9.0.58)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (8.5.0.96)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.7.91)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.7.99)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.7.4.91)
Requirement already satisfied: triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (2.0.0)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (11.4.0.1)
Requirement already satisfied: jinja2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch) (2.11.2)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == "Linux" and platform_machine == "x86_64" in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (10.2.10.91)
Requirement already satisfied: networkx in /home/kv2154/.local/lib/python3.8/site-packages (from torch) (3.1)
Requirement already satisfied: filelock in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torch) (3.0.12)
Requirement already satisfied: requests in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (2.24.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from torchvision) (8.0.1)
Requirement already satisfied: numpy in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages/numpy-1.19.2-py3.8-linux-x86_64.egg (from torchvision) (1.19.2)
Requirement already satisfied: setuptools in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == "Linux" and platform_machine == "x86_64"->torch) (49.2.1)
Requirement already satisfied: wheel in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from nvidia-cuda-cupti-cu11==11.7.101; platform_system == "Linux" and platform_machine == "x86_64"->torch) (0.35.1)
Requirement already satisfied: mpmath>=0.19 in /home/kv2154/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)
Requirement already satisfied: lit in /home/kv2154/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64"->torch) (16.0.2)
Requirement already satisfied: cmake in /home/kv2154/.local/lib/python3.8/site-packages (from triton==2.0.0; platform_system == "Linux" and platform_machine == "x86_64"->torch) (3.26.3)
Requirement already satisfied: MarkupSafe>=0.23 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (1.25.10)
Requirement already satisfied: idna<3,>=2.5 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2.10)
Requirement already satisfied: certifi>=2017.4.17 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (2020.6.20)
Requirement already satisfied: chardet<4,>=3.0.2 in /share/apps/python/3.8.6/intel/lib/python3.8/site-packages (from requests->torchvision) (3.0.4)
WARNING: You are using pip version 20.2.3; however, version 23.1.2 is available.
You should consider upgrading via the '/share/apps/python/3.8.6/intel/bin/python -m pip install --upgrade pip' command.
Files already downloaded and verified

Running with 1 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.5249, Accuracy 44.63%
Batch size: 32, Training time for epoch: 54.77 seconds
Batch size: 32, Communication time for epoch: 15.4883 seconds
Bandwidth utilization for 1 GPUs and batch size 32: 2.89 MB/sec
Epoch 2: Loss 1.0015, Accuracy 64.55%
Batch size: 32, Training time for epoch: 44.22 seconds
Batch size: 32, Communication time for epoch: 6.0116 seconds
Bandwidth utilization for 1 GPUs and batch size 32: 7.43 MB/sec

Running with 2 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.4370, Accuracy 48.23%
Batch size: 32, Training time for epoch: 25.52 seconds
Batch size: 32, Communication time for epoch: 4.5437 seconds
Bandwidth utilization for 2 GPUs and batch size 32: 9.84 MB/sec
Epoch 2: Loss 0.9397, Accuracy 66.86%
Batch size: 32, Training time for epoch: 23.94 seconds
Batch size: 32, Communication time for epoch: 3.0370 seconds
Bandwidth utilization for 2 GPUs and batch size 32: 14.72 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.4506, Accuracy 48.16%
Batch size: 32, Training time for epoch: 25.52 seconds
Batch size: 32, Communication time for epoch: 4.6555 seconds
Bandwidth utilization for 2 GPUs and batch size 32: 9.60 MB/sec
Epoch 2: Loss 0.9538, Accuracy 66.43%
Batch size: 32, Training time for epoch: 23.94 seconds
Batch size: 32, Communication time for epoch: 3.1361 seconds
Bandwidth utilization for 2 GPUs and batch size 32: 14.25 MB/sec

Running with 4 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.4820, Accuracy 45.89%
Batch size: 32, Training time for epoch: 13.93 seconds
Batch size: 32, Communication time for epoch: 3.1356 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 14.25 MB/sec
Epoch 2: Loss 0.9641, Accuracy 66.00%
Batch size: 32, Training time for epoch: 12.30 seconds
Batch size: 32, Communication time for epoch: 1.5710 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 28.45 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.4528, Accuracy 46.53%
Batch size: 32, Training time for epoch: 13.93 seconds
Batch size: 32, Communication time for epoch: 3.1716 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 14.09 MB/sec
Epoch 2: Loss 0.9444, Accuracy 66.90%
Batch size: 32, Training time for epoch: 12.30 seconds
Batch size: 32, Communication time for epoch: 1.6040 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 27.86 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.4879, Accuracy 45.97%
Batch size: 32, Training time for epoch: 13.94 seconds
Batch size: 32, Communication time for epoch: 3.1134 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 14.36 MB/sec
Epoch 2: Loss 0.9630, Accuracy 66.20%
Batch size: 32, Training time for epoch: 12.30 seconds
Batch size: 32, Communication time for epoch: 1.5948 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 28.03 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.4789, Accuracy 46.34%
Batch size: 32, Training time for epoch: 13.93 seconds
Batch size: 32, Communication time for epoch: 3.1647 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 14.12 MB/sec
Epoch 2: Loss 0.9640, Accuracy 65.62%
Batch size: 32, Training time for epoch: 12.30 seconds
Batch size: 32, Communication time for epoch: 1.5773 seconds
Bandwidth utilization for 4 GPUs and batch size 32: 28.34 MB/sec

Running with 1 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.4493, Accuracy 46.80%
Batch size: 128, Training time for epoch: 38.31 seconds
Batch size: 128, Communication time for epoch: 2.8510 seconds
Bandwidth utilization for 1 GPUs and batch size 128: 15.68 MB/sec
Epoch 2: Loss 0.9589, Accuracy 65.81%
Batch size: 128, Training time for epoch: 36.83 seconds
Batch size: 128, Communication time for epoch: 1.4729 seconds
Bandwidth utilization for 1 GPUs and batch size 128: 30.35 MB/sec

Running with 2 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.4734, Accuracy 45.82%
Batch size: 128, Training time for epoch: 20.64 seconds
Batch size: 128, Communication time for epoch: 2.2031 seconds
Bandwidth utilization for 2 GPUs and batch size 128: 20.29 MB/sec
Epoch 2: Loss 0.9753, Accuracy 65.36%
Batch size: 128, Training time for epoch: 19.20 seconds
Batch size: 128, Communication time for epoch: 0.7553 seconds
Bandwidth utilization for 2 GPUs and batch size 128: 59.17 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.4823, Accuracy 45.77%
Batch size: 128, Training time for epoch: 20.64 seconds
Batch size: 128, Communication time for epoch: 2.2397 seconds
Bandwidth utilization for 2 GPUs and batch size 128: 19.96 MB/sec
Epoch 2: Loss 0.9944, Accuracy 64.71%
Batch size: 128, Training time for epoch: 19.20 seconds
Batch size: 128, Communication time for epoch: 0.7846 seconds
Bandwidth utilization for 2 GPUs and batch size 128: 56.97 MB/sec

Running with 4 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.5637, Accuracy 41.42%
Batch size: 128, Training time for epoch: 11.39 seconds
Batch size: 128, Communication time for epoch: 1.8569 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 24.07 MB/sec
Epoch 2: Loss 1.0728, Accuracy 61.29%
Batch size: 128, Training time for epoch: 9.79 seconds
Batch size: 128, Communication time for epoch: 0.3967 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 112.67 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.5827, Accuracy 41.05%
Batch size: 128, Training time for epoch: 11.39 seconds
Batch size: 128, Communication time for epoch: 1.9353 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 23.09 MB/sec
Epoch 2: Loss 1.1066, Accuracy 60.40%
Batch size: 128, Training time for epoch: 9.79 seconds
Batch size: 128, Communication time for epoch: 0.4006 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 111.58 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.5849, Accuracy 41.52%
Batch size: 128, Training time for epoch: 11.39 seconds
Batch size: 128, Communication time for epoch: 1.8573 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 24.07 MB/sec
Epoch 2: Loss 1.1071, Accuracy 60.14%
Batch size: 128, Training time for epoch: 9.79 seconds
Batch size: 128, Communication time for epoch: 0.3992 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 111.97 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.5954, Accuracy 40.94%
Batch size: 128, Training time for epoch: 11.39 seconds
Batch size: 128, Communication time for epoch: 1.8874 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 23.68 MB/sec
Epoch 2: Loss 1.1053, Accuracy 59.72%
Batch size: 128, Training time for epoch: 9.79 seconds
Batch size: 128, Communication time for epoch: 0.3932 seconds
Bandwidth utilization for 4 GPUs and batch size 128: 113.68 MB/sec

Running with 1 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.5709, Accuracy 41.50%
Batch size: 512, Training time for epoch: 39.07 seconds
Batch size: 512, Communication time for epoch: 2.1909 seconds
Bandwidth utilization for 1 GPUs and batch size 512: 20.40 MB/sec
Epoch 2: Loss 1.0815, Accuracy 61.06%
Batch size: 512, Training time for epoch: 37.52 seconds
Batch size: 512, Communication time for epoch: 0.6489 seconds
Bandwidth utilization for 1 GPUs and batch size 512: 68.88 MB/sec

Running with 2 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.7350, Accuracy 35.35%
Batch size: 512, Training time for epoch: 20.45 seconds
Batch size: 512, Communication time for epoch: 1.8844 seconds
Bandwidth utilization for 2 GPUs and batch size 512: 23.72 MB/sec
Epoch 2: Loss 1.2542, Accuracy 54.45%
Batch size: 512, Training time for epoch: 18.85 seconds
Batch size: 512, Communication time for epoch: 0.3439 seconds
Bandwidth utilization for 2 GPUs and batch size 512: 129.96 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.7266, Accuracy 35.77%
Batch size: 512, Training time for epoch: 20.45 seconds
Batch size: 512, Communication time for epoch: 1.7422 seconds
Bandwidth utilization for 2 GPUs and batch size 512: 25.65 MB/sec
Epoch 2: Loss 1.2495, Accuracy 54.78%
Batch size: 512, Training time for epoch: 18.85 seconds
Batch size: 512, Communication time for epoch: 0.3442 seconds
Bandwidth utilization for 2 GPUs and batch size 512: 129.87 MB/sec

Running with 4 GPUs
Files already downloaded and verified
Epoch 1: Loss 1.9015, Accuracy 29.14%
Batch size: 512, Training time for epoch: 11.16 seconds
Batch size: 512, Communication time for epoch: 1.6333 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 27.36 MB/sec
Epoch 2: Loss 1.4680, Accuracy 45.88%
Batch size: 512, Training time for epoch: 9.61 seconds
Batch size: 512, Communication time for epoch: 0.1851 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 241.47 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.9140, Accuracy 28.96%
Batch size: 512, Training time for epoch: 11.16 seconds
Batch size: 512, Communication time for epoch: 1.6234 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 27.53 MB/sec
Epoch 2: Loss 1.4829, Accuracy 45.32%
Batch size: 512, Training time for epoch: 9.61 seconds
Batch size: 512, Communication time for epoch: 0.1777 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 251.52 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.9165, Accuracy 28.30%
Batch size: 512, Training time for epoch: 11.16 seconds
Batch size: 512, Communication time for epoch: 1.6424 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 27.21 MB/sec
Epoch 2: Loss 1.4855, Accuracy 44.99%
Batch size: 512, Training time for epoch: 9.61 seconds
Batch size: 512, Communication time for epoch: 0.1828 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 244.55 MB/sec
Files already downloaded and verified
Epoch 1: Loss 1.9157, Accuracy 28.21%
Batch size: 512, Training time for epoch: 11.16 seconds
Batch size: 512, Communication time for epoch: 1.6428 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 27.21 MB/sec
Epoch 2: Loss 1.4971, Accuracy 44.79%
Batch size: 512, Training time for epoch: 9.61 seconds
Batch size: 512, Communication time for epoch: 0.1811 seconds
Bandwidth utilization for 4 GPUs and batch size 512: 246.82 MB/sec
